{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Kanji with an MDN-RNN\n",
    "\n",
    "- What kind of data can be predicted by a mixture density network RNN?\n",
    "    - Sequential data that is _continuous_, not categorical.\n",
    "- Drawing data is a good example, tend to want high resolution in 2 dimensions to draw.\n",
    "    - not practical for categories\n",
    "- Let's try modelling some _drawing_ data using an MDN-RNN.\n",
    "- In this case we will use a dataset of Kanji\n",
    "\n",
    "This example is similar to hardmaru's Kanji tutorial and the original Sketch-RNN repository:\n",
    "\n",
    "- http://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/\n",
    "- https://github.com/hardmaru/sketch-rnn\n",
    "\n",
    "- The idea is to learn how to draw kanji characters from a dataset of vector representations. \n",
    "- This means learning how to move a pen in 2D space.\n",
    "- The data consists of a sequence of pen movements (loations in 2D) and whether the pen is up or down.\n",
    "- In this example, we will use one 3D MDN to model everything!\n",
    "\n",
    "We will end up with a system that can invent \"new\" kanji---but it won't know how to stop drawing! E.g.:\n",
    "\n",
    "![Kanji Test 1](figures/kanji_test_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import * # imports the MDN layer \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Only for GPU use:\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First download and process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train from David Ha's Kanji dataset from Sketch-RNN: https://github.com/hardmaru/sketch-rnn-datasets\n",
    "# Other datasets in \"Sketch 3\" format should also work.\n",
    "import urllib.request\n",
    "url = 'https://github.com/hardmaru/sketch-rnn-datasets/raw/master/kanji/kanji.rdp25.npz'  \n",
    "urllib.request.urlretrieve(url, './kanji.rdp25.npz')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "\n",
    "Includes about 11000 handwritten kanji characters divied into training, validation, and testing sets.\n",
    "\n",
    "For creative purposes, we may not need the validation or testing sets, and can just focus on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('./kanji.rdp25.npz', allow_pickle=True) as data:\n",
    "    train_set = data['train']\n",
    "    valid_set = data['valid']\n",
    "    test_set = data['test']\n",
    "    \n",
    "print(\"Training kanji:\", len(train_set))\n",
    "print(\"Validation kanji:\", len(valid_set))\n",
    "print(\"Testing kanji:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at one example\n",
    "\n",
    "Let's have a look at one example from the training data.\n",
    "\n",
    "- Each example is a sequence of pen movements with three numbers:\n",
    "    - The movement of the pen in the x-direction (left-right)\n",
    "    - The movement of the pen in the y-direction (up-down)\n",
    "    - Whether the pen is raised, or lowered touching the paper (1 = up, 0 = down).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the data.\n",
    "example = train_set[99]\n",
    "print(\"Shape:\", example.shape)\n",
    "print(example[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing a training example\n",
    "\n",
    "Lets try to plot this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(example.T[0], example.T[1])\n",
    "plt.title(\"Raw values (diffs) for one training example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That didn't work very well as we were just plotting the raw values\n",
    "    - (the difference between each pen movement)\n",
    "- We can transform these into paper locations by using the `cumsum()` function.\n",
    "- This will add each value to the sum of the previous in the array.\n",
    "\n",
    "Here's a proper sketch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(example.T[0].cumsum(), -1 * example.T[1].cumsum())\n",
    "plt.title(\"Accumulated values for one training example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that this sketch ignores the pen's touching or not value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup an MDN RNN\n",
    "\n",
    "So let's set up an MDN RNN to learn how to create similar drawings.\n",
    "\n",
    "Our RNN will have the following settings:\n",
    "\n",
    "- 2 RNN layers.\n",
    "- 256 LSTM units per RNN layer\n",
    "- a 3-dimensional mixture layer with 10 mixtures.\n",
    "- train for sequence length of 30.\n",
    "- training for 100 epochs with a batch size of 64.\n",
    "\n",
    "Here's a diagram:\n",
    "\n",
    "![Diagram of the Kanji MDN-RNN](figures/kanji-mdn-diagram.png)\n",
    "\n",
    "\n",
    "\n",
    "Why do we need a 3D mixture model?\n",
    "\n",
    "- One dimension for `pen-X`, one for `pen-Y`, and one for `pen-UpDown`\n",
    "- `pen-UpDown` isn't exactly a real number (it's either 0 or 1), but we can _make a simpler model_ by just adding another MDN dimension.\n",
    "- When doing predictions, we can just round the `pen-UpDown` value up to 1 or down to 0. Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 30\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_UNITS = 256\n",
    "EPOCHS = 100\n",
    "SEED = 2345  # set random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "OUTPUT_DIMENSION = 3\n",
    "NUMBER_MIXTURES = 10\n",
    "\n",
    "# Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add two LSTM layers, make sure the input shape of the first one is (?, 30, 3)\n",
    "model.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(None,SEQ_LEN,OUTPUT_DIMENSION), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(HIDDEN_UNITS))\n",
    "\n",
    "# Here's the MDN layer, need to specify the output dimension (3) and number of mixtures (10)\n",
    "model.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "\n",
    "# Now we compile the MDN RNN - need to use a special loss function with the right number of dimensions and mixtures.\n",
    "model.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "\n",
    "# Let's see what we have:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Data and Train the Model\n",
    "\n",
    "- Chop up the data into slices of the correct length, generate `X` and `y` for the training process.\n",
    "- Very similar process to the previous RNN examples!\n",
    "- We end up with 330000 examples - a pretty healthy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for slicing up data\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_singleton_format(examples):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:-1])\n",
    "        ys.append(ex[-1])\n",
    "    return (xs,ys)\n",
    "\n",
    "# Prepare training data as X and Y.\n",
    "slices = []\n",
    "for seq in train_set:\n",
    "    slices +=  slice_sequence_examples(seq, SEQ_LEN+1)\n",
    "X, y = seq_to_singleton_format(slices)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training!\n",
    "\n",
    "- We're not going to train in the tutorial!\n",
    "- These settings take about 220 seconds per epoch, about 6 hours for the whole training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[keras.callbacks.TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kanji_mdnrnn_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the model! Generate some Kanji!\n",
    "\n",
    "We need to create a decoding model with batch size 1 and sequence length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding Model\n",
    "# Same as training model except for dimension and mixtures.\n",
    "\n",
    "decoder = keras.Sequential()\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(1,1,OUTPUT_DIMENSION), return_sequences=True, stateful=True))\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, stateful=True))\n",
    "decoder.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "decoder.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "decoder.summary()\n",
    "\n",
    "decoder.load_weights('kanji_mdnrnn_model.h5') # load weights independently from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating drawings\n",
    "\n",
    "- First need some helper functions to view the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_start_position():\n",
    "    \"\"\"A zeroed out start position with pen down\"\"\"\n",
    "    out = np.zeros((1, 1, 3), dtype=np.float32)\n",
    "    out[0, 0, 2] = 1 # set pen down.\n",
    "    return out\n",
    "\n",
    "def generate_sketch(model, start_pos, num_points=100):\n",
    "     return None\n",
    "\n",
    "def cutoff_stroke(x):\n",
    "    return np.greater(x,0.5) * 1.0\n",
    "\n",
    "def plot_sketch(sketch_array):\n",
    "    \"\"\"Plot a sketch quickly to see what it looks like.\"\"\"\n",
    "    sketch_df = pd.DataFrame({'x':sketch_array.T[0],'y':sketch_array.T[1],'z':sketch_array.T[2]})\n",
    "    sketch_df.x = sketch_df.x.cumsum()\n",
    "    sketch_df.y = -1 * sketch_df.y.cumsum()\n",
    "    # Do the plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    #ax1.scatter(sketch_df.x,sketch_df.y,marker='o', c='r', alpha=1.0)\n",
    "    # Need to do something with sketch_df.z\n",
    "    ax1.plot(sketch_df.x,sketch_df.y,'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVG Drawing Function\n",
    "\n",
    "Here's Hardmaru's Drawing Functions from _write-rnn-tensorflow_. Big hat tip to Hardmaru for this!\n",
    "\n",
    "Here's the source: https://github.com/hardmaru/write-rnn-tensorflow/blob/master/utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardmaru's Drawing Functions from write-rnn-tensorflow\n",
    "# Big hat tip\n",
    "# Here's the source:\n",
    "# https://github.com/hardmaru/write-rnn-tensorflow/blob/master/utils.py\n",
    "\n",
    "import svgwrite\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "def get_bounds(data, factor):\n",
    "    min_x = 0\n",
    "    max_x = 0\n",
    "    min_y = 0\n",
    "    max_y = 0\n",
    "\n",
    "    abs_x = 0\n",
    "    abs_y = 0\n",
    "    for i in range(len(data)):\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        abs_x += x\n",
    "        abs_y += y\n",
    "        min_x = min(min_x, abs_x)\n",
    "        min_y = min(min_y, abs_y)\n",
    "        max_x = max(max_x, abs_x)\n",
    "        max_y = max(max_y, abs_y)\n",
    "\n",
    "    return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "def draw_strokes(data, factor=1, svg_filename='sample.svg'):\n",
    "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "\n",
    "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
    "\n",
    "    lift_pen = 1\n",
    "\n",
    "    abs_x = 25 - min_x\n",
    "    abs_y = 25 - min_y\n",
    "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "\n",
    "    command = \"m\"\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command + str(x) + \",\" + str(y) + \" \"\n",
    "\n",
    "    the_color = \"black\"\n",
    "    stroke_width = 1\n",
    "\n",
    "    dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(\"none\"))\n",
    "\n",
    "    dwg.save()\n",
    "    display(SVG(dwg.tostring()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict a character and plot the result.\n",
    "pi_temperature = 2.5 # seems to work well with rather high temperature (2.5)\n",
    "sigma_temp = 0.1 # seems to work well with low temp\n",
    "\n",
    "p = zero_start_position()\n",
    "sketch = [p.reshape(3,)]\n",
    "\n",
    "for i in range(400):\n",
    "    params = decoder.predict(p.reshape(1,1,3))\n",
    "    p = mdn.sample_from_output(params[0], OUTPUT_DIMENSION, NUMBER_MIXTURES, temp=pi_temperature, sigma_temp=sigma_temp)\n",
    "    sketch.append(p.reshape((3,)))\n",
    "\n",
    "sketch = np.array(sketch)\n",
    "decoder.reset_states()\n",
    "\n",
    "sketch.T[2] = cutoff_stroke(sketch.T[2])\n",
    "draw_strokes(sketch, factor=0.5)\n",
    "#plot_sketch(sketch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
